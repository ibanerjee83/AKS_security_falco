az account set --subscription subscription_number
az aks get-credentials --resource-group Rsg --name Akscluster


helm repo add falcosecurity https://falcosecurity.github.io/charts


testserver ~/.kube
$ helm repo add falcosecurity https://falcosecurity.github.io/charts
"falcosecurity" has been added to your repositories

testserver ~/.kube
$ helm repo list
NAME            URL
falcosecurity   https://falcosecurity.github.io/charts



helm repo update

$ helm repo update
Hang tight while we grab the latest from your chart repositories...
...Successfully got an update from the "falcosecurity" chart repository
Update Complete. ⎈ Happy Helming!⎈

testserver ~/.kube

$ kubectl create namespace falco
namespace/falco created



testserver ~/.kube
$ helm install falco -n falco --set falco.grpc.enabled=true --set falco.grpcOutput.enabled=true falcosecurity/falco
NAME: falco
LAST DEPLOYED: Mon Nov  9 14:20:55 2020
NAMESPACE: falco
STATUS: deployed
REVISION: 1
TEST SUITE: None
NOTES:
Falco agents are spinning up on each node in your cluster. After a few
seconds, they are going to start monitoring your containers looking for
security issues.
No further action should be required.

testserver ~/.kube
$ kubectl get namespaces
NAME                 STATUS   AGE
appconsolurlistio    Active   40d
argocd               Active   23d
default              Active   95d
ingress-controller   Active   95d
istio-system         Active   41d
kube-node-lease      Active   95d
kube-public          Active   95d
kube-system          Active   95d
rbac-manager         Active   95d
velero               Active   95d
falco                Active   103m    

testserver ~/.kube

$ kubectl get pod -n falco
NAME          READY   STATUS    RESTARTS   AGE
falco-nn47c   1/1     Running   0          2m20s
falco-q2clm   1/1     Running   0          2m20s
falco-rqf6r   1/1     Running   0          2m20s



$ helm install falco-exporter -n falco falcosecurity/falco-exporter
NAME: falco-exporter
LAST DEPLOYED: Mon Nov  9 17:42:58 2020
NAMESPACE: falco
STATUS: deployed
REVISION: 1
NOTES:
Get the falco-exporter metrics URL by running these commands:
  export POD_NAME=$(kubectl get pods --namespace falco -l "app.kubernetes.io/name=falco-exporter,app.kubernetes.io/instance=falco-exporter" -o jsonpath="{.items[0].metadata.name}")
  echo "Visit http://127.0.0.1:9376/metrics to use your application"
  kubectl port-forward --namespace falco $POD_NAME 9376




##############################################Uninstall falco#################################################################################################

$ helm uninstall falco -n falco
release "falco" uninstalled
kubectl create namespace falco

WeEu-S03-Tst-Aks-Aksc-99


testserver ~
$ kubectl get pod -n falco
NAME          READY   STATUS    RESTARTS   AGE
falco-4x7rz   1/1     Running   0          19m
falco-cgkfs   1/1     Running   0          19m
falco-vkqzb   1/1     Running   0          19m



$ kubectl exec -it falco-4x7rz ls -n falco
kubectl exec [POD] [COMMAND] is DEPRECATED and will be removed in a future version. Use kubectl kubectl exec [POD] -- [COMMAND] instead.
Unable to use a TTY - input is not a terminal or the right kind of file
bin
boot
dev
docker-entrypoint.sh
etc
home
host
lib
lib32
lib64
media
mnt
opt
proc
root
run
sbin
srv
sys
tmp
usr
var

$ kubectl exec -it falco-4x7rz cat etc/shadow  -n falco
kubectl exec [POD] [COMMAND] is DEPRECATED and will be removed in a future version. Use kubectl kubectl exec [POD] -- [COMMAND] instead.
Unable to use a TTY - input is not a terminal or the right kind of file
root:*:18513:0:99999:7:::
daemon:*:18513:0:99999:7:::
bin:*:18513:0:99999:7:::
sys:*:18513:0:99999:7:::
sync:*:18513:0:99999:7:::
games:*:18513:0:99999:7:::
man:*:18513:0:99999:7:::
lp:*:18513:0:99999:7:::
mail:*:18513:0:99999:7:::
news:*:18513:0:99999:7:::
uucp:*:18513:0:99999:7:::
proxy:*:18513:0:99999:7:::
www-data:*:18513:0:99999:7:::
backup:*:18513:0:99999:7:::
list:*:18513:0:99999:7:::
irc:*:18513:0:99999:7:::
gnats:*:18513:0:99999:7:::
nobody:*:18513:0:99999:7:::
_apt:*:18513:0:99999:7:::





$ kubectl get pod -n falco
NAME          READY   STATUS    RESTARTS   AGE
falco-4x7rz   1/1     Running   0          10s
falco-cgkfs   1/1     Running   0          10s
falco-vkqzb   1/1     Running   0          10s

testserver ~
$ kubectl logs -f falco-4x7rz  -n falco
* Setting up /usr/src links from host
* Running falco-driver-loader with: driver=module, compile=yes, download=yes
* Unloading falco module, if present
* Trying to dkms install falco module with GCC /usr/bin/gcc
DIRECTIVE: MAKE="'/tmp/falco-dkms-make'"

Kernel preparation unnecessary for this kernel.  Skipping...

Building module:
cleaning build area....
'/tmp/falco-dkms-make'........
cleaning build area....

DKMS: build completed.

falco.ko:
Running module version sanity check.

depmod...

DKMS: install completed.
* falco module installed in dkms, trying to insmod
* Success: falco module found and loaded in dkms
Tue Nov 10 10:36:20 2020: Falco version 0.26.1 (driver version 2aa88dcf6243982697811df4c1b484bcbe9488a2)
Tue Nov 10 10:36:20 2020: Falco initialized with configuration file /etc/falco/falco.yaml
Tue Nov 10 10:36:20 2020: Loading rules from file /etc/falco/falco_rules.yaml:
Tue Nov 10 10:36:20 2020: Loading rules from file /etc/falco/falco_rules.local.yaml:
Tue Nov 10 10:36:22 2020: Starting internal webserver, listening on port 8765

11:09:01.058023281: Warning Sensitive file opened for reading by non-trusted program (user=root user_loginuid=-1 program=cat command=cat etc/shadow file=/etc/shadow parent=<NA> gparent=<NA> ggparent=<NA> gggparent=<NA> container_id=b8e84d5d9d83 image=falcosecurity/falco) k8s.ns=falco k8s.pod=falco-4x7rz container=b8e84d5d9d83 k8s.ns=falco k8s.pod=falco-4x7rz container=b8e84d5d9d83




$ kubectl port-forward falco-4x7rz -n falco 8765:8765


#######################33 Contariner entrering ################33333



$ winpty kubectl exec -it falco-jbsx9 bash -n falco
kubectl exec [POD] [COMMAND] is DEPRECATED and will be removed in a future version. Use kubectl kubectl exec [POD] -- [COMMAND] instead.
root@falco-jbsx9:/# hostname
falco-jbsx9
root@falco-jbsx9:/#




################## Logstash ###########################################################################


$ kubectl create namespace logstash
namespace/logstash created



$ kubectl get namespace
NAME                 STATUS   AGE
appconsolurlistio    Active   41d
argocd               Active   25d
default              Active   96d
falco                Active   40h
ingress-controller   Active   96d
istio-system         Active   42d
kube-node-lease      Active   96d
kube-public          Active   96d
kube-system          Active   96d
logstash             Active   8s
pritam-test          Active   13h
rbac-manager         Active   96d
velero               Active   96d

 
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$%%%%%%%%%% This log stach not required $$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$

$ helm repo add elastic https://helm.elastic.co
"elastic" has been added to your repositories

 



########### Logtash helm chart values.yml  update ############################## 

logstashConfig: 
  logstash.yml: |
    http.host: "0.0.0.0"
    path.config: /usr/share/logstash/pipeline  
#   key:
#   nestedkey: value
#  log4j2.properties: |
#    key = value
#
# Allows you to add any pipeline files in /usr/share/logstash/pipeline/
### ***warn*** there is a hardcoded logstash.conf in the image, override it first

logstashPipeline: 
  logstash.conf: |
    input {
       file {
          path => "/var/log/pods/falco*/*.log"
            }
         }
#     filter {
#         }    
        
#     output {
#        microsoft-logstash-output-azure-loganalytics {
#           workspace_id => d4e88b17-b48d-4cf9-91bd-0ee977596500
#           workspace_key => /Mvi3NX4s6SXnDT4BnqBWE698jJUbE2YkUcf40IrEVvClkPMY/IhxSwf0aD2NKV57QUYNFqg37OQzNbNWKlWBg==
#           custom_log_table_name => "falcoName"    
#          } 
#        }  
# Extra environment variables to append to this nodeGroup
# This will be appended to the current 'env:' key. You can use any of the kubernetes env
# syntax here
extraEnvs: []
#  - name: MY_ENVIRONMENT_VAR
#    value: the_value_goes_here

# Allows you to load environment variables from kubernetes secret or config map
#envFrom: [] 
envFrom: 
# - secretRef:
#     name: env-secret
  - configMapRef:
      name: logstash-configmap


####################################################################################


 helm install logstash . -n logging
$  helm upgrade logstash . -n logging
Release "logstash" has been upgraded. Happy Helming!
NAME: logstash
LAST DEPLOYED: Thu Nov 12 19:19:59 2020
NAMESPACE: logging
STATUS: deployed
REVISION: 6
TEST SUITE: None
NOTES:
1. Watch all cluster members come up.
  $ kubectl get pods --namespace=logging -l app=logstash-logstash -w



$ kubectl logs -f logstash-logstash-0 -n logging
Using bundled JDK: /usr/share/logstash/jdk
OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
Sending Logstash logs to /usr/share/logstash/logs which is now configured via log4j2.properties
[2020-11-12T18:20:38,244][INFO ][logstash.runner          ] Starting Logstash {"logstash.version"=>"8.0.0", "jruby.version"=>"jruby 9.2.13.0 (2.5.7) 2020-08-03 9a89c94bcc OpenJDK 64-Bit Server VM 11.0.8+10 on 11.0.8+10 +indy +jit [linux-x86_64]"}
[2020-11-12T18:20:38,328][INFO ][logstash.setting.writabledirectory] Creating directory {:setting=>"path.queue", :path=>"/usr/share/logstash/data/queue"}
[2020-11-12T18:20:38,335][INFO ][logstash.setting.writabledirectory] Creating directory {:setting=>"path.dead_letter_queue", :path=>"/usr/share/logstash/data/dead_letter_queue"}
[2020-11-12T18:20:39,016][WARN ][logstash.config.source.multilocal] Ignoring the 'pipelines.yml' file because modules or command line options are specified
[2020-11-12T18:20:39,033][INFO ][logstash.agent           ] No persistent UUID file found. Generating new UUID {:uuid=>"b247d124-0db3-4b23-a51b-83c20f81ec74", :path=>"/usr/share/logstash/data/uuid"}
[2020-11-12T18:20:40,823][INFO ][org.reflections.Reflections] Reflections took 57 ms to scan 1 urls, producing 23 keys and 47 values
[2020-11-12T18:20:41,520][INFO ][logstash.javapipeline    ][main] Starting pipeline {:pipeline_id=>"main", "pipeline.workers"=>1, "pipeline.batch.size"=>125, "pipeline.batch.delay"=>50, "pipeline.max_inflight"=>125, "pipeline.sources"=>["/usr/share/logstash/pipeline/logstash.conf"], :thread=>"#<Thread:0x69ba996e run>"}
[2020-11-12T18:20:41,531][INFO ][logstash.javapipeline    ][main] Pipeline Java execution initialization time {"seconds"=>0.01}
[2020-11-12T18:20:41,847][INFO ][logstash.inputs.file     ][main] No sincedb_path set, generating one based on the "path" setting {:sincedb_path=>"/usr/share/logstash/data/plugins/inputs/file/.sincedb_c6846d283e195bbeaf8d4aeeee83f97e", :path=>["/var/log/pods/falco*/sirene_update/*.log"]}
[2020-11-12T18:20:41,918][INFO ][logstash.javapipeline    ][main] Pipeline started {"pipeline.id"=>"main"}
[2020-11-12T18:20:42,016][INFO ][filewatch.observingtail  ][main][fd940b8756e048de9dec0d7edd0767400914b644a3629ceeb17316e2ace69562] START, creating Discoverer, Watch with file and sincedb collections
[2020-11-12T18:20:42,031][INFO ][logstash.agent           ] Pipelines running {:count=>1, :running_pipelines=>[:main], :non_running_pipelines=>[]}
[2020-11-12T18:20:42,419][INFO ][logstash.agent           ] Successfully started Logstash API endpoint {:port=>9600}





############################################### Log stash correct repo #################################################################


https://github.com/helm/charts/tree/master/stable/logstash







###################################################################################################################################





helm install falco -n falco \
  --set falco.grpc.enabled=true \
  --set falco.grpcOutput.enabled=true \
  --set falco.syslogOutput.enabled=true \
  --set falco.fileOutput.keepAlive=true \
  --set falco.fileOutput.enabled=true \
   --set falco.fileOutput.filename="/var/run/falco/falcolog" \
  --set falco.stdoutOutput.enabled=true \
  --set falco.jsonOutput=true \
  falcosecurity/falco
  
        helm upgrade --install falco --namespace falco \
      ./${{ parameters['folder'] }}/helmcharts/falco \
      -f ./${{ parameters['folder'] }}/helmcharts/falco/values.yaml
  
  
helm install falco -n falco \
  --set falco.grpc.enabled=true \
  --set falco.grpcOutput.enabled=true \
  --set falco.syslogOutput.enabled=true \
  --set falco.fileOutput.keepAlive=true \
  --set falco.fileOutput.enabled=true \
  --set falco.stdoutOutput.enabled=true \
  --set falco.jsonOutput=true \
  falcosecurity/falco
  
  
  
helm install falco . -n falco
  winpty kubectl exec -it falco-5l2xr bash -n falco


helm upgrade logstash . -n logging
